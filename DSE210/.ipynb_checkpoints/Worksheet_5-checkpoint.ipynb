{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Class Distribution\n",
    "\n",
    "#### Calculate fraction of documents in each class\n",
    "\n",
    "$$\\pi_j = \\frac{class_{j}}{\\sum\\limits_{n=1}^{20} class_{n} }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of each class:\n",
      "1: 0.04259472890229834\n",
      "2: 0.05155736977549028\n",
      "3: 0.05075871860857219\n",
      "4: 0.05208980388676901\n",
      "5: 0.051024935664211554\n",
      "6: 0.052533498979501284\n",
      "7: 0.051646108794036735\n",
      "8: 0.052533498979501284\n",
      "9: 0.052888455053687104\n",
      "10: 0.0527109770165942\n",
      "11: 0.05306593309078002\n",
      "12: 0.0527109770165942\n",
      "13: 0.05244475996095483\n",
      "14: 0.0527109770165942\n",
      "15: 0.052622237998047744\n",
      "16: 0.05315467210932647\n",
      "17: 0.04836276510781791\n",
      "18: 0.05004880646020055\n",
      "19: 0.04117490460555506\n",
      "20: 0.033365870973467035\n"
     ]
    }
   ],
   "source": [
    "#Training label\n",
    "train_label = open('/home/sadat/Downloads/HW2_210/20news-bydate/matlab/train.label')\n",
    "\n",
    "#pi is the fraction of each class\n",
    "pi = {}\n",
    "\n",
    "#Set a class index for each document as key\n",
    "for i in range(1,21):\n",
    "    pi[i] = 0\n",
    "    \n",
    "#Extract values from training labels\n",
    "lines = train_label.readlines()\n",
    "\n",
    "#Get total number of documents\n",
    "total = len(lines)\n",
    "\n",
    "#Count the occurence of each class\n",
    "for line in lines:\n",
    "    val = int(line.split()[0])\n",
    "    pi[val] += 1\n",
    "\n",
    "#Divide the count of each class by total documents \n",
    "for key in pi:\n",
    "    pi[key] /= total\n",
    "    \n",
    "print(\"Probability of each class:\")\n",
    "print(\"\\n\".join(\"{}: {}\".format(k, v) for k, v in pi.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if sum of the probabilities is 1\n",
    "np.sum(list(pi.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Probability Distribution over V\n",
    "\n",
    "####Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docIdx</th>\n",
       "      <th>wordIdx</th>\n",
       "      <th>count</th>\n",
       "      <th>classIdx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docIdx  wordIdx  count  classIdx\n",
       "0       1        1      4         1\n",
       "1       1        2      2         1\n",
       "2       1        3     10         1\n",
       "3       1        4      4         1\n",
       "4       1        5      2         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training data\n",
    "train_data = open('/home/sadat/Downloads/HW2_210/20news-bydate/matlab/train.data')\n",
    "df = pd.read_csv(train_data, delimiter=' ', names=['docIdx', 'wordIdx', 'count'])\n",
    "\n",
    "#Training label\n",
    "label = []\n",
    "train_label = open('/home/sadat/Downloads/HW2_210/20news-bydate/matlab/train.label')\n",
    "lines = train_label.readlines()\n",
    "for line in lines:\n",
    "    label.append(int(line.split()[0]))\n",
    "\n",
    "#Increase label length to match docIdx\n",
    "docIdx = df['docIdx'].values\n",
    "i = 0\n",
    "new_label = []\n",
    "for index in range(len(docIdx)-1):\n",
    "    new_label.append(label[i])\n",
    "    if docIdx[index] != docIdx[index+1]:\n",
    "        i += 1\n",
    "new_label.append(label[i]) #for-loop ignores last value\n",
    "\n",
    "#Add label column\n",
    "df['classIdx'] = new_label\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Probability of each word per class\n",
    "\n",
    "For calculating our probability, we will find the average of each word for a given class.\n",
    "\n",
    "For class j and word i, the average is given by:\n",
    "\n",
    "$$P(i|j) = \\frac{word_{ij}}{word_j}$$\n",
    "\n",
    "\n",
    "However, since some words will have 0 counts, we will perform a Laplace Smoothing:\n",
    "\n",
    "\n",
    "\n",
    "$$ P(i|j) = \\frac{word_{ij}+\\alpha}{word_j+|V|+1}, \\alpha = 0.1$$\n",
    "\n",
    "where $V$ is an array of all the words in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>wordIdx</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>53966</th>\n",
       "      <th>53967</th>\n",
       "      <th>53968</th>\n",
       "      <th>53969</th>\n",
       "      <th>53970</th>\n",
       "      <th>53971</th>\n",
       "      <th>53972</th>\n",
       "      <th>53973</th>\n",
       "      <th>53974</th>\n",
       "      <th>53975</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classIdx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.915360e-05</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>1.662226e-03</td>\n",
       "      <td>5.498456e-05</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>3.685778e-05</td>\n",
       "      <td>6.646486e-06</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>8.465206e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>6.042260e-07</td>\n",
       "      <td>6.042260e-07</td>\n",
       "      <td>6.042260e-07</td>\n",
       "      <td>6.042260e-07</td>\n",
       "      <td>6.042260e-07</td>\n",
       "      <td>6.042260e-07</td>\n",
       "      <td>6.042260e-07</td>\n",
       "      <td>6.042260e-07</td>\n",
       "      <td>6.042260e-07</td>\n",
       "      <td>6.042260e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.730533e-04</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>7.871103e-07</td>\n",
       "      <td>1.345959e-04</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>7.949814e-05</td>\n",
       "      <td>4.801373e-05</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>2.440042e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>7.871103e-07</td>\n",
       "      <td>7.871103e-07</td>\n",
       "      <td>7.871103e-07</td>\n",
       "      <td>7.871103e-07</td>\n",
       "      <td>7.871103e-07</td>\n",
       "      <td>7.871103e-07</td>\n",
       "      <td>7.871103e-07</td>\n",
       "      <td>7.871103e-07</td>\n",
       "      <td>7.871103e-07</td>\n",
       "      <td>7.871103e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.032981e-04</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>9.306135e-07</td>\n",
       "      <td>1.591349e-04</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>1.954288e-05</td>\n",
       "      <td>1.954288e-05</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>9.306135e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>9.306135e-07</td>\n",
       "      <td>9.306135e-07</td>\n",
       "      <td>9.306135e-07</td>\n",
       "      <td>9.306135e-07</td>\n",
       "      <td>9.306135e-07</td>\n",
       "      <td>9.306135e-07</td>\n",
       "      <td>9.306135e-07</td>\n",
       "      <td>9.306135e-07</td>\n",
       "      <td>9.306135e-07</td>\n",
       "      <td>9.306135e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.992705e-05</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>8.632969e-07</td>\n",
       "      <td>8.632969e-07</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>1.812924e-05</td>\n",
       "      <td>9.496266e-06</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>8.632969e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>8.632969e-07</td>\n",
       "      <td>8.632969e-07</td>\n",
       "      <td>8.632969e-07</td>\n",
       "      <td>8.632969e-07</td>\n",
       "      <td>8.632969e-07</td>\n",
       "      <td>8.632969e-07</td>\n",
       "      <td>8.632969e-07</td>\n",
       "      <td>8.632969e-07</td>\n",
       "      <td>8.632969e-07</td>\n",
       "      <td>8.632969e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.929296e-05</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>9.720157e-07</td>\n",
       "      <td>1.069217e-05</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>1.069217e-05</td>\n",
       "      <td>9.720157e-07</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>9.720157e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>9.720157e-07</td>\n",
       "      <td>9.720157e-07</td>\n",
       "      <td>9.720157e-07</td>\n",
       "      <td>9.720157e-07</td>\n",
       "      <td>9.720157e-07</td>\n",
       "      <td>9.720157e-07</td>\n",
       "      <td>9.720157e-07</td>\n",
       "      <td>9.720157e-07</td>\n",
       "      <td>9.720157e-07</td>\n",
       "      <td>9.720157e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.778187e-04</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>5.898487e-07</td>\n",
       "      <td>4.665703e-04</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>1.244581e-04</td>\n",
       "      <td>1.828531e-05</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>5.898487e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>5.898487e-07</td>\n",
       "      <td>5.898487e-07</td>\n",
       "      <td>5.898487e-07</td>\n",
       "      <td>5.898487e-07</td>\n",
       "      <td>5.898487e-07</td>\n",
       "      <td>5.898487e-07</td>\n",
       "      <td>5.898487e-07</td>\n",
       "      <td>5.898487e-07</td>\n",
       "      <td>5.898487e-07</td>\n",
       "      <td>5.898487e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.285628e-06</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>1.285628e-06</td>\n",
       "      <td>2.699819e-05</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>1.285628e-06</td>\n",
       "      <td>1.285628e-06</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>3.985447e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.285628e-06</td>\n",
       "      <td>1.285628e-06</td>\n",
       "      <td>1.285628e-06</td>\n",
       "      <td>1.285628e-06</td>\n",
       "      <td>1.285628e-06</td>\n",
       "      <td>1.285628e-06</td>\n",
       "      <td>1.285628e-06</td>\n",
       "      <td>1.285628e-06</td>\n",
       "      <td>1.285628e-06</td>\n",
       "      <td>1.285628e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.957665e-05</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>7.645786e-07</td>\n",
       "      <td>7.645786e-07</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>5.428508e-05</td>\n",
       "      <td>2.370194e-05</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>7.645786e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>7.645786e-07</td>\n",
       "      <td>7.645786e-07</td>\n",
       "      <td>7.645786e-07</td>\n",
       "      <td>7.645786e-07</td>\n",
       "      <td>7.645786e-07</td>\n",
       "      <td>7.645786e-07</td>\n",
       "      <td>7.645786e-07</td>\n",
       "      <td>7.645786e-07</td>\n",
       "      <td>7.645786e-07</td>\n",
       "      <td>7.645786e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.181696e-04</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>8.380825e-07</td>\n",
       "      <td>3.436138e-05</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>2.598056e-05</td>\n",
       "      <td>9.218907e-06</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>8.380825e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>8.380825e-07</td>\n",
       "      <td>8.380825e-07</td>\n",
       "      <td>8.380825e-07</td>\n",
       "      <td>8.380825e-07</td>\n",
       "      <td>8.380825e-07</td>\n",
       "      <td>8.380825e-07</td>\n",
       "      <td>8.380825e-07</td>\n",
       "      <td>8.380825e-07</td>\n",
       "      <td>8.380825e-07</td>\n",
       "      <td>8.380825e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.829172e-06</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>8.026520e-07</td>\n",
       "      <td>1.685569e-05</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>8.829172e-06</td>\n",
       "      <td>8.026520e-07</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>8.026520e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>8.026520e-07</td>\n",
       "      <td>8.026520e-07</td>\n",
       "      <td>8.026520e-07</td>\n",
       "      <td>8.026520e-07</td>\n",
       "      <td>8.026520e-07</td>\n",
       "      <td>8.026520e-07</td>\n",
       "      <td>8.026520e-07</td>\n",
       "      <td>8.026520e-07</td>\n",
       "      <td>8.026520e-07</td>\n",
       "      <td>8.026520e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.963965e-06</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>6.330877e-07</td>\n",
       "      <td>6.330877e-07</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>1.329484e-05</td>\n",
       "      <td>5.128010e-05</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>6.330877e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>6.330877e-07</td>\n",
       "      <td>6.330877e-07</td>\n",
       "      <td>6.330877e-07</td>\n",
       "      <td>6.330877e-07</td>\n",
       "      <td>6.330877e-07</td>\n",
       "      <td>6.330877e-07</td>\n",
       "      <td>6.330877e-07</td>\n",
       "      <td>6.330877e-07</td>\n",
       "      <td>6.330877e-07</td>\n",
       "      <td>6.330877e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.399318e-04</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>4.605218e-07</td>\n",
       "      <td>5.111792e-05</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>1.155910e-04</td>\n",
       "      <td>3.269705e-05</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>4.605218e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>4.605218e-07</td>\n",
       "      <td>4.605218e-07</td>\n",
       "      <td>4.605218e-07</td>\n",
       "      <td>4.605218e-07</td>\n",
       "      <td>4.605218e-07</td>\n",
       "      <td>4.605218e-07</td>\n",
       "      <td>4.605218e-07</td>\n",
       "      <td>4.605218e-07</td>\n",
       "      <td>4.605218e-07</td>\n",
       "      <td>4.605218e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.586308e-05</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>8.342928e-07</td>\n",
       "      <td>1.752015e-05</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>4.254893e-05</td>\n",
       "      <td>1.752015e-05</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>8.342928e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>8.342928e-07</td>\n",
       "      <td>8.342928e-07</td>\n",
       "      <td>8.342928e-07</td>\n",
       "      <td>8.342928e-07</td>\n",
       "      <td>8.342928e-07</td>\n",
       "      <td>8.342928e-07</td>\n",
       "      <td>8.342928e-07</td>\n",
       "      <td>8.342928e-07</td>\n",
       "      <td>8.342928e-07</td>\n",
       "      <td>8.342928e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.777692e-05</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>5.813041e-07</td>\n",
       "      <td>7.615084e-05</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>6.394345e-06</td>\n",
       "      <td>5.289867e-05</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>5.813041e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>5.813041e-07</td>\n",
       "      <td>5.813041e-07</td>\n",
       "      <td>5.813041e-07</td>\n",
       "      <td>5.813041e-07</td>\n",
       "      <td>5.813041e-07</td>\n",
       "      <td>5.813041e-07</td>\n",
       "      <td>5.813041e-07</td>\n",
       "      <td>5.813041e-07</td>\n",
       "      <td>5.813041e-07</td>\n",
       "      <td>5.813041e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.822720e-04</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>5.868441e-07</td>\n",
       "      <td>1.296926e-04</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>1.355610e-04</td>\n",
       "      <td>5.340282e-05</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>5.868441e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>5.868441e-07</td>\n",
       "      <td>5.868441e-07</td>\n",
       "      <td>5.868441e-07</td>\n",
       "      <td>5.868441e-07</td>\n",
       "      <td>5.868441e-07</td>\n",
       "      <td>5.868441e-07</td>\n",
       "      <td>5.868441e-07</td>\n",
       "      <td>5.868441e-07</td>\n",
       "      <td>5.868441e-07</td>\n",
       "      <td>5.868441e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.588082e-07</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>7.386812e-05</td>\n",
       "      <td>3.257538e-05</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>4.588082e-07</td>\n",
       "      <td>4.588082e-07</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>2.573914e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>4.588082e-07</td>\n",
       "      <td>4.588082e-07</td>\n",
       "      <td>4.588082e-07</td>\n",
       "      <td>4.588082e-07</td>\n",
       "      <td>4.588082e-07</td>\n",
       "      <td>4.588082e-07</td>\n",
       "      <td>4.588082e-07</td>\n",
       "      <td>4.588082e-07</td>\n",
       "      <td>4.588082e-07</td>\n",
       "      <td>4.588082e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.916772e-05</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>5.192027e-07</td>\n",
       "      <td>3.167137e-05</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>1.090326e-05</td>\n",
       "      <td>4.205542e-05</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>5.192027e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>5.192027e-07</td>\n",
       "      <td>5.192027e-07</td>\n",
       "      <td>5.192027e-07</td>\n",
       "      <td>5.192027e-07</td>\n",
       "      <td>5.192027e-07</td>\n",
       "      <td>5.192027e-07</td>\n",
       "      <td>5.192027e-07</td>\n",
       "      <td>5.192027e-07</td>\n",
       "      <td>5.192027e-07</td>\n",
       "      <td>5.192027e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.720156e-05</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>3.683323e-07</td>\n",
       "      <td>3.351824e-05</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>2.983491e-05</td>\n",
       "      <td>1.108680e-04</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>4.051655e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.683323e-07</td>\n",
       "      <td>3.683323e-07</td>\n",
       "      <td>3.683323e-07</td>\n",
       "      <td>3.683323e-07</td>\n",
       "      <td>3.683323e-07</td>\n",
       "      <td>3.683323e-07</td>\n",
       "      <td>3.683323e-07</td>\n",
       "      <td>3.683323e-07</td>\n",
       "      <td>3.683323e-07</td>\n",
       "      <td>3.683323e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.923319e-07</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>4.923319e-07</td>\n",
       "      <td>1.137287e-04</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>5.415651e-06</td>\n",
       "      <td>8.418876e-05</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>4.923319e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>4.923319e-07</td>\n",
       "      <td>4.923319e-07</td>\n",
       "      <td>4.923319e-07</td>\n",
       "      <td>4.923319e-07</td>\n",
       "      <td>4.923319e-07</td>\n",
       "      <td>4.923319e-07</td>\n",
       "      <td>4.923319e-07</td>\n",
       "      <td>4.923319e-07</td>\n",
       "      <td>4.923319e-07</td>\n",
       "      <td>4.923319e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.364584e-07</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>6.701771e-05</td>\n",
       "      <td>1.546563e-05</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>3.755938e-05</td>\n",
       "      <td>8.101042e-06</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>3.755938e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>8.101042e-06</td>\n",
       "      <td>8.101042e-06</td>\n",
       "      <td>1.546563e-05</td>\n",
       "      <td>8.101042e-06</td>\n",
       "      <td>8.101042e-06</td>\n",
       "      <td>8.101042e-06</td>\n",
       "      <td>8.101042e-06</td>\n",
       "      <td>8.101042e-06</td>\n",
       "      <td>8.101042e-06</td>\n",
       "      <td>8.101042e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 53975 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "wordIdx          1         2             3             4         5      \\\n",
       "classIdx                                                                 \n",
       "1         7.915360e-05  0.000381  1.662226e-03  5.498456e-05  0.000496   \n",
       "2         4.730533e-04  0.000465  7.871103e-07  1.345959e-04  0.000111   \n",
       "3         1.032981e-04  0.000643  9.306135e-07  1.591349e-04  0.000196   \n",
       "4         6.992705e-05  0.000268  8.632969e-07  8.632969e-07  0.000087   \n",
       "5         5.929296e-05  0.000322  9.720157e-07  1.069217e-05  0.000011   \n",
       "6         2.778187e-04  0.001310  5.898487e-07  4.665703e-04  0.000089   \n",
       "7         1.285628e-06  0.000361  1.285628e-06  2.699819e-05  0.000027   \n",
       "8         6.957665e-05  0.000414  7.645786e-07  7.645786e-07  0.000100   \n",
       "9         1.181696e-04  0.000562  8.380825e-07  3.436138e-05  0.000034   \n",
       "10        8.829172e-06  0.000266  8.026520e-07  1.685569e-05  0.000009   \n",
       "11        6.963965e-06  0.000425  6.330877e-07  6.330877e-07  0.000007   \n",
       "12        2.399318e-04  0.000415  4.605218e-07  5.111792e-05  0.000272   \n",
       "13        2.586308e-05  0.000276  8.342928e-07  1.752015e-05  0.000043   \n",
       "14        8.777692e-05  0.000227  5.813041e-07  7.615084e-05  0.000117   \n",
       "15        2.822720e-04  0.000482  5.868441e-07  1.296926e-04  0.000071   \n",
       "16        4.588082e-07  0.000565  7.386812e-05  3.257538e-05  0.000065   \n",
       "17        9.916772e-05  0.000172  5.192027e-07  3.167137e-05  0.000058   \n",
       "18        3.720156e-05  0.000568  3.683323e-07  3.351824e-05  0.000008   \n",
       "19        4.923319e-07  0.000193  4.923319e-07  1.137287e-04  0.000084   \n",
       "20        7.364584e-07  0.000332  6.701771e-05  1.546563e-05  0.000170   \n",
       "\n",
       "wordIdx      6             7             8         9             10     \\\n",
       "classIdx                                                                 \n",
       "1         0.000248  3.685778e-05  6.646486e-06  0.000206  8.465206e-04   \n",
       "2         0.000457  7.949814e-05  4.801373e-05  0.001355  2.440042e-05   \n",
       "3         0.000317  1.954288e-05  1.954288e-05  0.001341  9.306135e-07   \n",
       "4         0.000415  1.812924e-05  9.496266e-06  0.000415  8.632969e-07   \n",
       "5         0.000458  1.069217e-05  9.720157e-07  0.000458  9.720157e-07   \n",
       "6         0.000307  1.244581e-04  1.828531e-05  0.001399  5.898487e-07   \n",
       "7         0.000413  1.285628e-06  1.285628e-06  0.000361  3.985447e-05   \n",
       "8         0.000658  5.428508e-05  2.370194e-05  0.000138  7.645786e-07   \n",
       "9         0.000696  2.598056e-05  9.218907e-06  0.000034  8.380825e-07   \n",
       "10        0.002425  8.829172e-06  8.026520e-07  0.000017  8.026520e-07   \n",
       "11        0.001324  1.329484e-05  5.128010e-05  0.000026  6.330877e-07   \n",
       "12        0.000373  1.155910e-04  3.269705e-05  0.000512  4.605218e-07   \n",
       "13        0.000251  4.254893e-05  1.752015e-05  0.000243  8.342928e-07   \n",
       "14        0.000402  6.394345e-06  5.289867e-05  0.000146  5.813041e-07   \n",
       "15        0.000599  1.355610e-04  5.340282e-05  0.000141  5.868441e-07   \n",
       "16        0.000464  4.588082e-07  4.588082e-07  0.000078  2.573914e-04   \n",
       "17        0.000551  1.090326e-05  4.205542e-05  0.000099  5.192027e-07   \n",
       "18        0.000575  2.983491e-05  1.108680e-04  0.000037  4.051655e-06   \n",
       "19        0.000744  5.415651e-06  8.418876e-05  0.000050  4.923319e-07   \n",
       "20        0.000325  3.755938e-05  8.101042e-06  0.000141  3.755938e-05   \n",
       "\n",
       "wordIdx       ...              53966         53967         53968  \\\n",
       "classIdx      ...                                                  \n",
       "1             ...       6.042260e-07  6.042260e-07  6.042260e-07   \n",
       "2             ...       7.871103e-07  7.871103e-07  7.871103e-07   \n",
       "3             ...       9.306135e-07  9.306135e-07  9.306135e-07   \n",
       "4             ...       8.632969e-07  8.632969e-07  8.632969e-07   \n",
       "5             ...       9.720157e-07  9.720157e-07  9.720157e-07   \n",
       "6             ...       5.898487e-07  5.898487e-07  5.898487e-07   \n",
       "7             ...       1.285628e-06  1.285628e-06  1.285628e-06   \n",
       "8             ...       7.645786e-07  7.645786e-07  7.645786e-07   \n",
       "9             ...       8.380825e-07  8.380825e-07  8.380825e-07   \n",
       "10            ...       8.026520e-07  8.026520e-07  8.026520e-07   \n",
       "11            ...       6.330877e-07  6.330877e-07  6.330877e-07   \n",
       "12            ...       4.605218e-07  4.605218e-07  4.605218e-07   \n",
       "13            ...       8.342928e-07  8.342928e-07  8.342928e-07   \n",
       "14            ...       5.813041e-07  5.813041e-07  5.813041e-07   \n",
       "15            ...       5.868441e-07  5.868441e-07  5.868441e-07   \n",
       "16            ...       4.588082e-07  4.588082e-07  4.588082e-07   \n",
       "17            ...       5.192027e-07  5.192027e-07  5.192027e-07   \n",
       "18            ...       3.683323e-07  3.683323e-07  3.683323e-07   \n",
       "19            ...       4.923319e-07  4.923319e-07  4.923319e-07   \n",
       "20            ...       8.101042e-06  8.101042e-06  1.546563e-05   \n",
       "\n",
       "wordIdx          53969         53970         53971         53972  \\\n",
       "classIdx                                                           \n",
       "1         6.042260e-07  6.042260e-07  6.042260e-07  6.042260e-07   \n",
       "2         7.871103e-07  7.871103e-07  7.871103e-07  7.871103e-07   \n",
       "3         9.306135e-07  9.306135e-07  9.306135e-07  9.306135e-07   \n",
       "4         8.632969e-07  8.632969e-07  8.632969e-07  8.632969e-07   \n",
       "5         9.720157e-07  9.720157e-07  9.720157e-07  9.720157e-07   \n",
       "6         5.898487e-07  5.898487e-07  5.898487e-07  5.898487e-07   \n",
       "7         1.285628e-06  1.285628e-06  1.285628e-06  1.285628e-06   \n",
       "8         7.645786e-07  7.645786e-07  7.645786e-07  7.645786e-07   \n",
       "9         8.380825e-07  8.380825e-07  8.380825e-07  8.380825e-07   \n",
       "10        8.026520e-07  8.026520e-07  8.026520e-07  8.026520e-07   \n",
       "11        6.330877e-07  6.330877e-07  6.330877e-07  6.330877e-07   \n",
       "12        4.605218e-07  4.605218e-07  4.605218e-07  4.605218e-07   \n",
       "13        8.342928e-07  8.342928e-07  8.342928e-07  8.342928e-07   \n",
       "14        5.813041e-07  5.813041e-07  5.813041e-07  5.813041e-07   \n",
       "15        5.868441e-07  5.868441e-07  5.868441e-07  5.868441e-07   \n",
       "16        4.588082e-07  4.588082e-07  4.588082e-07  4.588082e-07   \n",
       "17        5.192027e-07  5.192027e-07  5.192027e-07  5.192027e-07   \n",
       "18        3.683323e-07  3.683323e-07  3.683323e-07  3.683323e-07   \n",
       "19        4.923319e-07  4.923319e-07  4.923319e-07  4.923319e-07   \n",
       "20        8.101042e-06  8.101042e-06  8.101042e-06  8.101042e-06   \n",
       "\n",
       "wordIdx          53973         53974         53975  \n",
       "classIdx                                            \n",
       "1         6.042260e-07  6.042260e-07  6.042260e-07  \n",
       "2         7.871103e-07  7.871103e-07  7.871103e-07  \n",
       "3         9.306135e-07  9.306135e-07  9.306135e-07  \n",
       "4         8.632969e-07  8.632969e-07  8.632969e-07  \n",
       "5         9.720157e-07  9.720157e-07  9.720157e-07  \n",
       "6         5.898487e-07  5.898487e-07  5.898487e-07  \n",
       "7         1.285628e-06  1.285628e-06  1.285628e-06  \n",
       "8         7.645786e-07  7.645786e-07  7.645786e-07  \n",
       "9         8.380825e-07  8.380825e-07  8.380825e-07  \n",
       "10        8.026520e-07  8.026520e-07  8.026520e-07  \n",
       "11        6.330877e-07  6.330877e-07  6.330877e-07  \n",
       "12        4.605218e-07  4.605218e-07  4.605218e-07  \n",
       "13        8.342928e-07  8.342928e-07  8.342928e-07  \n",
       "14        5.813041e-07  5.813041e-07  5.813041e-07  \n",
       "15        5.868441e-07  5.868441e-07  5.868441e-07  \n",
       "16        4.588082e-07  4.588082e-07  4.588082e-07  \n",
       "17        5.192027e-07  5.192027e-07  5.192027e-07  \n",
       "18        3.683323e-07  3.683323e-07  3.683323e-07  \n",
       "19        4.923319e-07  4.923319e-07  4.923319e-07  \n",
       "20        8.101042e-06  8.101042e-06  8.101042e-06  \n",
       "\n",
       "[20 rows x 53975 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alpha value for smoothing\n",
    "a = 0.001\n",
    "\n",
    "#Calculate probability of each word based on class\n",
    "pb_ij = df.groupby(['classIdx','wordIdx'])\n",
    "pb_j = df.groupby(['classIdx'])\n",
    "Pr =  (pb_ij['count'].sum() + a) / (pb_j['count'].sum() + 16689)    \n",
    "\n",
    "#Unstack series\n",
    "Pr = Pr.unstack()\n",
    "\n",
    "#Replace NaN or columns with 0 as word count with 1/(count+|V|+1)\n",
    "for c in range(1,21):\n",
    "    Pr.loc[c,:] = Pr.loc[c,:].fillna(a/(pb_j['count'].sum()[c] + 16689))\n",
    "\n",
    "#Convert to dictionary for greater speed\n",
    "Pr_dict = Pr.to_dict()\n",
    "\n",
    "Pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Stop Words\n",
    "\n",
    "Setting all stop words to count 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Common stop words from online\n",
    "stop_words = [\"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \n",
    "    \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
    "    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
    "    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n",
    "    \"as\", \"at\", \"be\", \"became\", \"because\", \"become\",\n",
    "    \"becomes\", \"becoming\", \"been\", \"before\", \"behind\", \"being\",\n",
    "    \"beside\", \"besides\", \"between\", \"beyond\", \"both\",\n",
    "    \"but\", \"by\",\"can\", \"cannot\", \"cant\",\n",
    "    \"could\", \"couldnt\", \"de\", \"describe\", \"do\", \"done\",\n",
    "    \"each\", \"eg\", \"either\", \"else\",\n",
    "    \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
    "    \"everything\", \"everywhere\", \"except\", \"few\",\n",
    "    \"find\",\"for\",\"found\", \"four\", \"from\", \"further\", \"get\", \"give\", \"go\",\n",
    "    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n",
    "    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n",
    "    \"how\", \"however\", \"i\", \"ie\", \"if\", \"in\", \"indeed\",\n",
    "    \"is\", \"it\", \"its\", \"itself\", \"keep\",\n",
    "    \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n",
    "    \"meanwhile\", \"might\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n",
    "    \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n",
    "    \"never\", \"nevertheless\", \"next\",\"no\", \"nobody\", \"none\", \"noone\",\n",
    "    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n",
    "    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n",
    "    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\",\"perhaps\",\n",
    "    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n",
    "    \"seeming\", \"seems\", \"she\", \"should\",\"since\", \"sincere\",\"so\", \"some\", \"somehow\", \"someone\",\n",
    "    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
    "    \"take\",\"than\", \"that\", \"the\", \"their\", \"them\",\n",
    "    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
    "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\",\n",
    "    \"this\", \"those\", \"though\", \"through\", \"throughout\",\n",
    "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"toward\", \"towards\",\n",
    "    \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
    "    \"very\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
    "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \n",
    "    \"who\", \"whoever\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
    "    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "    \"yourselves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>archive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>resources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>alt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       word\n",
       "0      1    archive\n",
       "1      2       name\n",
       "2      3    atheism\n",
       "3      4  resources\n",
       "4      5        alt"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = open('/home/sadat/Downloads/HW2_210/vocabulary.txt')\n",
    "vocab_df = pd.read_csv(vocab, names = ['word'])\n",
    "vocab_df = vocab_df.reset_index()\n",
    "vocab_df['index'] = vocab_df['index'].apply(lambda x: x+1)\n",
    "vocab_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 250 stop words\n"
     ]
    }
   ],
   "source": [
    "#Index of all words\n",
    "tot_list = set(vocab_df['index'])\n",
    "\n",
    "#Index of good words\n",
    "for word in stop_words:\n",
    "    vocab_df = vocab_df[vocab_df['word'] != word]\n",
    "good_list = vocab_df['index'].tolist()\n",
    "good_list = set(good_list)\n",
    "\n",
    "#Index of stop words\n",
    "bad_list = tot_list - good_list\n",
    "\n",
    "print('There are',len(bad_list),'stop words')\n",
    "\n",
    "#Set all stop words to 0\n",
    "for bad in bad_list:\n",
    "    for j in range(1,21):\n",
    "        Pr_dict[j][bad] = 1/(pb_j['count'].sum()[j] + 16689)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Multinomial Naive Bayes Classifier\n",
    "\n",
    "Combining probability distribution of P with fraction of documents belonging to each class. \n",
    "\n",
    "For class <b>j</b>, word <b>i</b> at a word frequency of <b>f</b>:\n",
    "\n",
    "$$Pr(j) = \\pi_j \\prod\\limits_{i=1}^{|V|} Pr(i|j)^{f_i}$$\n",
    "#### \n",
    "In order to avoid underflow, we will use the sum of logs:\n",
    "\n",
    "$$Pr(j) = \\log\\pi_j  + \\sum\\limits_{i=1}^{|V|} f_i\\log(Pr(i|j))$$\n",
    "#### \n",
    "One issue is that, if a word appears again, the probability of it appearing again goes up. In order to smooth this, we take the log of the frequency:\n",
    "\n",
    "$$Pr(j) = \\log\\pi_j + \\sum\\limits_{i=1}^{|V|} log(1+f_i)\\log(Pr(i|j))$$\n",
    "#### \n",
    "Also, in order to take stop words into account, we will add a Inverse Document Frequency weight on each word:\n",
    "\n",
    "$$t_i = \\log(\\dfrac{\\sum\\limits_{n=1}^{N} doc_n}{doc_i})$$\n",
    "#### \n",
    "$$Pr(j) = \\log\\pi_j + \\sum\\limits_{i=1}^{|V|} f_i\\log(t_iPr(i|j))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Create dictionaries for Word probabilites and Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate IDF\n",
    "tot = len(df['docIdx'].unique())\n",
    "pb_ij = df.groupby(['wordIdx'])\n",
    "IDF = np.log(tot/pb_ij['docIdx'].count())\n",
    "IDF_dict = IDF.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Generating function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MNB(df, smooth = False, IDF = False):\n",
    "    '''\n",
    "    Multinomial Naive Bayes classifier\n",
    "    :param df [Pandas Dataframe]: Dataframe of data\n",
    "    :param smooth [bool]: Apply Smoothing if True\n",
    "    :param IDF [bool]: Apply Inverse Document Frequency if True\n",
    "    :return predict [list]: Predicted class ID\n",
    "    '''\n",
    "    #Using dictionaries for greater speed\n",
    "    df_dict = df.to_dict()\n",
    "    new_dict = {}\n",
    "    prediction = []\n",
    "    \n",
    "    #new_dict = {docIdx : {wordIdx: count},....}\n",
    "    for idx in range(len(df_dict['docIdx'])):\n",
    "        docIdx = df_dict['docIdx'][idx]\n",
    "        wordIdx = df_dict['wordIdx'][idx]\n",
    "        count = df_dict['count'][idx]\n",
    "        try: \n",
    "            new_dict[docIdx][wordIdx] = count \n",
    "        except:\n",
    "            new_dict[df_dict['docIdx'][idx]] = {}\n",
    "            new_dict[docIdx][wordIdx] = count\n",
    "\n",
    "    #Calculating the scores for each doc\n",
    "    for docIdx in range(1, len(new_dict)+1):\n",
    "        score_dict = {}\n",
    "        #Creating a probability row for each class\n",
    "        for classIdx in range(1,21):\n",
    "            score_dict[classIdx] = 1\n",
    "            #For each word:\n",
    "            for wordIdx in new_dict[docIdx]:\n",
    "                #Check for frequency smoothing\n",
    "                #log(1+f)*log(Pr(i|j))\n",
    "                if smooth: \n",
    "                    try:\n",
    "                        probability = Pr_dict[wordIdx][classIdx]         #Pr(i|j)\n",
    "                        power = np.log(1+ new_dict[docIdx][wordIdx])     #log(1+f)\n",
    "                        #Check for IDF\n",
    "                        if IDF:\n",
    "                            score_dict[classIdx] += power*np.log(probability*IDF_dict[wordIdx])\n",
    "                        else:\n",
    "                            score_dict[classIdx] += power*np.log(probability)\n",
    "                    except:\n",
    "                        #Missing V will have log(1+0)*log(a/16689)=0 \n",
    "                        score_dict[classIdx] += 0                        \n",
    "                #f*log(Pr(i|j))\n",
    "                else: \n",
    "                    try:\n",
    "                        probability = Pr_dict[wordIdx][classIdx]        #Pr(i|j)\n",
    "                        power = new_dict[docIdx][wordIdx]               #f\n",
    "                        score_dict[classIdx] += power*np.log(probability) \n",
    "                        #Check for IDF\n",
    "                        if IDF:\n",
    "                            score_dict[classIdx] += power*np.log(probability*IDF_dict[wordIdx]) \n",
    "                    except:\n",
    "                        #Missing V will have 0*log(a/16689) = 0\n",
    "                        score_dict[classIdx] += 0      \n",
    "            #Multiply final with pi         \n",
    "            score_dict[classIdx] +=  np.log(pi[classIdx])                          \n",
    "\n",
    "        #Get class with max probabilty for the given docIdx \n",
    "        max_score = max(score_dict, key=score_dict.get)\n",
    "        prediction.append(max_score)\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Comparing the effects of  Smoothing and IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regular_predict = MNB(df, smooth=False, IDF=False)\n",
    "smooth_predict  = MNB(df, smooth=True, IDF=False)\n",
    "tfidf_predict   = MNB(df, smooth=False, IDF=True)\n",
    "all_predict     = MNB(df, smooth=True, IDF=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get list of labels\n",
    "train_label = pd.read_csv('/home/sadat/Downloads/HW2_210/20news-bydate/matlab/train.label', names=['t'])\n",
    "train_label= train_label['t'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Error:\t\t 4.197355577247316 %\n",
      "Smooth Error:\t\t 2.6089271452657736 %\n",
      "IDF Error:\t\t 4.206229479101961 %\n",
      "Both Error:\t\t 2.6089271452657736 %\n"
     ]
    }
   ],
   "source": [
    "total = len(train_label)\n",
    "models = [regular_predict, smooth_predict, tfidf_predict, all_predict]\n",
    "strings = ['Regular', 'Smooth', 'IDF', 'Both']\n",
    "\n",
    "for m,s in zip(models,strings):\n",
    "    val = 0\n",
    "    for i,j in zip(m, train_label):\n",
    "        if i != j:\n",
    "            val +=1\n",
    "        else:\n",
    "            pass   \n",
    "    print(s,\"Error:\\t\\t\",val/total * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As we can see, smoothing makes our model worse while IDF makes the model mode accurate. Hence, our optimal model is:\n",
    "$$Pr(j) = \\log\\pi_j + \\sum\\limits_{i=1}^{|V|} log(1+f_i)\\log(Pr(i|j))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:\t 20.87941372418388 %\n"
     ]
    }
   ],
   "source": [
    "#Get test data\n",
    "test_data = open('/home/sadat/Downloads/HW2_210/20news-bydate/matlab/test.data')\n",
    "df = pd.read_csv(test_data, delimiter=' ', names=['docIdx', 'wordIdx', 'count'])\n",
    "\n",
    "#Get list of labels\n",
    "test_label = pd.read_csv('/home/sadat/Downloads/HW2_210/20news-bydate/matlab/test.label', names=['t'])\n",
    "test_label= test_label['t'].tolist()\n",
    "\n",
    "#MNB Calculation\n",
    "predict = MNB(df, smooth = True, IDF = False)\n",
    "\n",
    "total = len(test_label)\n",
    "val = 0\n",
    "for i,j in zip(predict, test_label):\n",
    "    if i == j:\n",
    "        val +=1\n",
    "    else:\n",
    "        pass\n",
    "print(\"Error:\\t\",(1-(val/total)) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
